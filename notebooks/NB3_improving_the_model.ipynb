{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "# third party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# local imports\n",
    "from BERT_geoparser.data import Data, Phrase\n",
    "from BERT_geoparser.tokenizer import Tokenizer\n",
    "from BERT_geoparser.model import BertModel\n",
    "from BERT_geoparser.analysis import Results\n",
    "from BERT_geoparser.retagger import Retagger\n",
    "from BERT_geoparser.utils import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on randomized locations\n",
    "While these results are promising, there is a serious flaw in the datset the model has been trained on. Specifically, the reviews are from businesses from a small number of locations. As such, there is a danger that the model is simply consistently assigning the `tar` tag to tokens matching those places. To investigate we will build a new dataset with all the tokens tagged as `tar` replaced with random draws from a list of place names. \n",
    "\n",
    "One approach to doing this would be to go through the test data and replace anything tagged as a target location with a new location. However, this will cause problems with indexing if the token representation of the new location is longer or shorter than the previous location (e.g. ['New', 'York'] -> ['LA']). \n",
    "\n",
    "To get around any problems with indexing we willgenerate a new reviews dataset, with the text and coordinates altered when a place tagged as `tar` is mentioned. We will then go through the process of NER tagging and `tar`/`inc` tagging again to produce a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jshin\\Documents\\Work\\DSO\\BERT_geoparser\\BERT_geoparser\\retagger.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df.loc[:, 'sequential_group'] = groups\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>B-art</th>\n",
       "      <th>B-eve</th>\n",
       "      <th>B-geo</th>\n",
       "      <th>B-gpe</th>\n",
       "      <th>B-nat</th>\n",
       "      <th>B-org</th>\n",
       "      <th>B-per</th>\n",
       "      <th>...</th>\n",
       "      <th>I-geo</th>\n",
       "      <th>I-gpe</th>\n",
       "      <th>I-nat</th>\n",
       "      <th>I-org</th>\n",
       "      <th>I-per</th>\n",
       "      <th>I-tim</th>\n",
       "      <th>O</th>\n",
       "      <th>old_tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>sequential_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>phil</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>##ly</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>897</td>\n",
       "      <td>9</td>\n",
       "      <td>shell</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.041</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>898</td>\n",
       "      <td>9</td>\n",
       "      <td>key</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.027</td>\n",
       "      <td>I-geo</td>\n",
       "      <td>I-tar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>899</td>\n",
       "      <td>9</td>\n",
       "      <td>island</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.084</td>\n",
       "      <td>I-geo</td>\n",
       "      <td>I-tar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Sentence #    Word  B-art  B-eve  B-geo  B-gpe  B-nat  B-org  \\\n",
       "66      66           0    phil  0.000  0.000  0.981  0.001  0.000  0.007   \n",
       "67      67           0    ##ly  0.000  0.000  0.987  0.001  0.000  0.006   \n",
       "897    897           9   shell  0.037  0.003  0.469  0.002  0.001  0.358   \n",
       "898    898           9     key  0.004  0.002  0.061  0.001  0.001  0.004   \n",
       "899    899           9  island  0.002  0.000  0.011  0.001  0.000  0.002   \n",
       "\n",
       "     B-per  ...  I-geo  I-gpe  I-nat  I-org  I-per  I-tim      O  old_tag  \\\n",
       "66   0.000  ...  0.001  0.000  0.000  0.000  0.000  0.000  0.005    B-geo   \n",
       "67   0.000  ...  0.002  0.000  0.000  0.000  0.000  0.000  0.002    B-geo   \n",
       "897  0.047  ...  0.011  0.000  0.001  0.015  0.002  0.002  0.041    B-geo   \n",
       "898  0.009  ...  0.583  0.003  0.001  0.212  0.048  0.004  0.027    I-geo   \n",
       "899  0.002  ...  0.619  0.002  0.001  0.218  0.023  0.003  0.084    I-geo   \n",
       "\n",
       "       Tag  sequential_group  \n",
       "66   B-tar                 0  \n",
       "67   B-tar                 0  \n",
       "897  B-tar                 1  \n",
       "898  I-tar                 1  \n",
       "899  I-tar                 1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the test data\n",
    "test_data = pd.read_csv('data/step_4/test_yelp_dataset.csv')\n",
    "# extract only lines tagged as target\n",
    "target_only_data = test_data[test_data.Tag.str.contains('tar')]\n",
    "# use the Retagger class to add a 'sequential group' column to this data.\n",
    "retagger = Retagger(target_only_data)\n",
    "retagger.add_sequential_groups()\n",
    "retagger.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset of world cities, and produce a list of US cities and a (lat,long) coordinate for that city. This will be important for re-tagging the dataset as `tar` and `inc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cities_df = pd.read_csv('data/model_improvement/worldcities.csv')\n",
    "us_cities_df = world_cities_df[world_cities_df.iso3=='USA']\n",
    "us_cities = []\n",
    "for i, city in us_cities_df.iterrows():\n",
    "    name = city.city_ascii\n",
    "    lat = city.lat\n",
    "    lng = city.lng\n",
    "    us_cities.append({'name':name, 'coords':str((lat,lng))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to loop over the test locations in the test dataset (i.e. groups of sequentially indexed tokens tagged as `tar`) and create a dictionary which maps the review number (`Sentence #`) to a copy of the review text with the location replaced with a random draw from the cities dataset and the set of coordinates related to the new location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('data/step_2/25k_yelp_reviews_with_location.csv', nrows=25000)[20000:]\n",
    "review_df = review_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Blue Claws can be pricey but phenomenal. Stick with the larges i/o jumbo, sizes very close and save some $. Great with fries and beer. I've never had anything but those 3 things so couldn't tell you much else but worth the visit if you're looking for crabs in Philly.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want the word 'Philly' to be replaced with another random city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for replacements, mapping a review index to a new  \n",
    "replacement_dict = {}\n",
    "\n",
    "for i, group in retagger.df.groupby('sequential_group'):\n",
    "    # build the phrase for this group of words\n",
    "    old_name = Phrase('', tag=None)\n",
    "    for token, tag in zip(group['Word'].values, group['Tag'].values):\n",
    "        old_name.add_token(token=token, tag=tag)\n",
    "    # get a new city and coordinate pair\n",
    "    new_city = random.choice(us_cities)\n",
    "    # get the old text and replace the city name\n",
    "    review_num = group['Sentence #'].iloc[0]\n",
    "    old_text = review_df.loc[review_num].text.lower()\n",
    "    new_text = old_text.replace(old_name.text, new_city['name'])\n",
    "    # update the review dataframe\n",
    "    review_df.loc[review_num, 'text'] = new_text\n",
    "    review_df.loc[review_num, 'coordinates'] = new_city['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"blue claws can be pricey but phenomenal. stick with the larges i/o jumbo, sizes very close and save some $. great with fries and beer. i've never had anything but those 3 things so couldn't tell you much else but worth the visit if you're looking for crabs in Yelm.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to have worked! We can now build a new test datset out of this randomized data and see if the model is able to acheive an acceptable degree of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 125)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 125)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 125)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
      "                                thPoolingAndCrossAt               'input_3[0][0]',                \n",
      "                                tentions(last_hidde               'input_2[0][0]']                \n",
      "                                n_state=(None, 125,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 125, 768)     0           ['tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 125, 18)      13842       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,496,082\n",
      "Trainable params: 109,496,082\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [15:12<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#### NER Tagging ###\n",
    "data_csv = r'../data/ner_dataset.csv'\n",
    "tokenizer = Tokenizer(size='base', cased=False)\n",
    "data = Data(data_path=data_csv, \n",
    "            tokenizer=tokenizer,\n",
    "            max_len=125)\n",
    "\n",
    "model = BertModel(saved_model='20230808_bert_model_large.hdf5', data=data)\n",
    "model.model.summary()\n",
    "\n",
    "results = model.results_dataframe(texts=review_df.text.values, include_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jshin\\Documents\\Work\\DSO\\BERT_geoparser\\BERT_geoparser\\retagger.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df.loc[:, 'sequential_group'] = groups\n",
      "100%|██████████| 5744/5744 [48:44<00:00,  1.96it/s]  \n"
     ]
    }
   ],
   "source": [
    "### tar/inc tagging\n",
    "retagger = Retagger(results)\n",
    "retagger.retag(['geo', 'gpe', 'org'], threshold='bbox', review_df=review_df)\n",
    "retagged_data = retagger.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>B-art</th>\n",
       "      <th>B-eve</th>\n",
       "      <th>B-geo</th>\n",
       "      <th>B-gpe</th>\n",
       "      <th>B-nat</th>\n",
       "      <th>B-org</th>\n",
       "      <th>B-per</th>\n",
       "      <th>B-tim</th>\n",
       "      <th>...</th>\n",
       "      <th>I-eve</th>\n",
       "      <th>I-geo</th>\n",
       "      <th>I-gpe</th>\n",
       "      <th>I-nat</th>\n",
       "      <th>I-org</th>\n",
       "      <th>I-per</th>\n",
       "      <th>I-tim</th>\n",
       "      <th>O</th>\n",
       "      <th>old_tag</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.357</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>claws</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.597</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>can</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>be</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>ye</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.014</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>##lm</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.053</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #   Word  B-art  B-eve  B-geo  B-gpe  B-nat  B-org  B-per  B-tim  \\\n",
       "0            0  [CLS]  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "1            0   blue  0.220  0.008  0.057  0.004  0.004  0.288  0.043  0.005   \n",
       "2            0  claws  0.010  0.001  0.007  0.001  0.001  0.018  0.022  0.001   \n",
       "3            0    can  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "4            0     be  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "65           0     in  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "66           0     ye  0.006  0.000  0.908  0.002  0.000  0.045  0.005  0.010   \n",
       "67           0   ##lm  0.012  0.001  0.803  0.002  0.001  0.084  0.010  0.023   \n",
       "68           0      .  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "69           0  [SEP]  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "\n",
       "    ...  I-eve  I-geo  I-gpe  I-nat  I-org  I-per  I-tim      O  old_tag  \\\n",
       "0   ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  1.000        O   \n",
       "1   ...  0.001  0.003  0.001  0.001  0.004  0.002  0.001  0.357        O   \n",
       "2   ...  0.006  0.046  0.001  0.003  0.216  0.024  0.001  0.597        O   \n",
       "3   ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  1.000        O   \n",
       "4   ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  1.000        O   \n",
       "..  ...    ...    ...    ...    ...    ...    ...    ...    ...      ...   \n",
       "65  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  1.000        O   \n",
       "66  ...  0.000  0.007  0.000  0.000  0.001  0.000  0.001  0.014    B-geo   \n",
       "67  ...  0.001  0.006  0.000  0.000  0.001  0.001  0.002  0.053    B-geo   \n",
       "68  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  1.000        O   \n",
       "69  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  1.000        O   \n",
       "\n",
       "      Tag  \n",
       "0       O  \n",
       "1       O  \n",
       "2       O  \n",
       "3       O  \n",
       "4       O  \n",
       "..    ...  \n",
       "65      O  \n",
       "66  B-tar  \n",
       "67  B-tar  \n",
       "68      O  \n",
       "69      O  \n",
       "\n",
       "[70 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retagged_data[retagged_data['Sentence #']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retagged_data.to_csv('data/step_4/test_yelp_dataset_randomized_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 512s 3s/step\n"
     ]
    }
   ],
   "source": [
    "data_csv = 'data/step_4/test_yelp_dataset_randomized_locations.csv'\n",
    "tokenizer = Tokenizer(size='base', cased=False)\n",
    "data = Data(data_path=data_csv, \n",
    "            tokenizer=tokenizer,\n",
    "            max_len=125)\n",
    "tar_model = BertModel(saved_model='20230926_tar_tagged_bert_model_large.hdf5', data=data)\n",
    "X_tokens, y_pred, y_true = tar_model.test('data/step_4/test_yelp_dataset_randomized_locations.csv', return_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"O\" accuracy : 0.994\n",
      "\"O\" precision : 0.991\n",
      "\"O\" recall : 0.994\n",
      "=======================\n",
      "\"tar\" accuracy : 0.354\n",
      "\"tar\" precision : 0.528\n",
      "\"tar\" recall : 0.354\n",
      "=======================\n",
      "\"inc\" accuracy : 0.68\n",
      "\"inc\" precision : 0.734\n",
      "\"inc\" recall : 0.69\n",
      "=======================\n",
      "macro average recall : 0.575\n",
      "macro average precision : 0.698\n",
      "micro average recall : 0.981\n",
      "micro average precision : 0.981\n"
     ]
    }
   ],
   "source": [
    "res = Results(y_true, y_pred)\n",
    "for cat in ['O', 'tar', 'inc']:\n",
    "    print(f'\"{cat}\" accuracy : {np.round(res.categorical_accuracy(cat),3)}')\n",
    "    print(f'\"{cat}\" precision : {np.round(res.categorical_precision(cat),3)}')\n",
    "    print(f'\"{cat}\" recall : {np.round(res.categorical_recall(cat),3)}')\n",
    "    print('=======================')\n",
    "print(f'macro average recall : {np.round(res.macro_average_recall(), 3)}')\n",
    "print(f'macro average precision : {np.round(res.macro_average_precision(),3)}')\n",
    "print(f'micro average recall : {np.round(res.micro_average_recall(),3)}')\n",
    "print(f'micro average precision : {np.round(res.micro_average_precision(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not good. The model clearly struggles with the randomized location data, indicating that the high accuracy acheived on the previous dataset was likely a product of the limited location, rather than any understanding of sentence structure. \n",
    "\n",
    "## Re-train the model on randomized location data\n",
    "The first approach to this should be to retrain the model on the new data. This will help the model generalise a little better about locations, but may result in some of the finer nuance in the data being lost. Contextual information, such as foods, activities or sights specific to a particular location, will be lost. This highlights one of the key limitations of the yelp data. With data which is already more generalised this contextualisation might be possible. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jshin\\Documents\\Work\\DSO\\BERT_geoparser\\BERT_geoparser\\retagger.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df.loc[:, 'sequential_group'] = groups\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>B-art</th>\n",
       "      <th>B-eve</th>\n",
       "      <th>B-geo</th>\n",
       "      <th>B-gpe</th>\n",
       "      <th>B-nat</th>\n",
       "      <th>B-org</th>\n",
       "      <th>B-per</th>\n",
       "      <th>...</th>\n",
       "      <th>I-geo</th>\n",
       "      <th>I-gpe</th>\n",
       "      <th>I-nat</th>\n",
       "      <th>I-org</th>\n",
       "      <th>I-per</th>\n",
       "      <th>I-tim</th>\n",
       "      <th>O</th>\n",
       "      <th>old_tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>sequential_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>phil</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>##ly</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>897</td>\n",
       "      <td>9</td>\n",
       "      <td>shell</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.041</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-tar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>898</td>\n",
       "      <td>9</td>\n",
       "      <td>key</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.027</td>\n",
       "      <td>I-geo</td>\n",
       "      <td>I-tar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>899</td>\n",
       "      <td>9</td>\n",
       "      <td>island</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.084</td>\n",
       "      <td>I-geo</td>\n",
       "      <td>I-tar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Sentence #    Word  B-art  B-eve  B-geo  B-gpe  B-nat  B-org  \\\n",
       "66      66           0    phil  0.000  0.000  0.981  0.001  0.000  0.007   \n",
       "67      67           0    ##ly  0.000  0.000  0.987  0.001  0.000  0.006   \n",
       "897    897           9   shell  0.037  0.003  0.469  0.002  0.001  0.358   \n",
       "898    898           9     key  0.004  0.002  0.061  0.001  0.001  0.004   \n",
       "899    899           9  island  0.002  0.000  0.011  0.001  0.000  0.002   \n",
       "\n",
       "     B-per  ...  I-geo  I-gpe  I-nat  I-org  I-per  I-tim      O  old_tag  \\\n",
       "66   0.000  ...  0.001  0.000  0.000  0.000  0.000  0.000  0.005    B-geo   \n",
       "67   0.000  ...  0.002  0.000  0.000  0.000  0.000  0.000  0.002    B-geo   \n",
       "897  0.047  ...  0.011  0.000  0.001  0.015  0.002  0.002  0.041    B-geo   \n",
       "898  0.009  ...  0.583  0.003  0.001  0.212  0.048  0.004  0.027    I-geo   \n",
       "899  0.002  ...  0.619  0.002  0.001  0.218  0.023  0.003  0.084    I-geo   \n",
       "\n",
       "       Tag  sequential_group  \n",
       "66   B-tar                 0  \n",
       "67   B-tar                 0  \n",
       "897  B-tar                 1  \n",
       "898  I-tar                 1  \n",
       "899  I-tar                 1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a new training set\n",
    "# open the test data\n",
    "train_data = pd.read_csv('data/step_4/test_yelp_dataset.csv')\n",
    "# extract only lines tagged as target\n",
    "target_only_data = train_data[train_data.Tag.str.contains('tar')]\n",
    "# use the Retagger class to add a 'sequential group' column to this data.\n",
    "retagger = Retagger(target_only_data)\n",
    "retagger.add_sequential_groups()\n",
    "retagger.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('data/step_2/25k_yelp_reviews_with_location.csv', nrows=25000)\n",
    "review_df = review_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for replacements, mapping a review index to a new  \n",
    "replacement_dict = {}\n",
    "\n",
    "for i, group in retagger.df.groupby('sequential_group'):\n",
    "    # build the phrase for this group of words\n",
    "    old_name = Phrase('', tag=None)\n",
    "    for token, tag in zip(group['Word'].values, group['Tag'].values):\n",
    "        old_name.add_token(token=token, tag=tag)\n",
    "    # get a new city and coordinate pair\n",
    "    new_city = random.choice(us_cities)\n",
    "    # get the old text and replace the city name\n",
    "    review_num = group['Sentence #'].iloc[0]\n",
    "    old_text = review_df.loc[review_num].text.lower()\n",
    "    new_text = old_text.replace(old_name.text, new_city['name'])\n",
    "    # update the review dataframe\n",
    "    review_df.loc[review_num, 'text'] = new_text\n",
    "    review_df.loc[review_num, 'coordinates'] = new_city['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 125)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 125)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 125)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
      "                                thPoolingAndCrossAt               'input_3[0][0]',                \n",
      "                                tentions(last_hidde               'input_2[0][0]']                \n",
      "                                n_state=(None, 125,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 125, 768)     0           ['tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 125, 18)      13842       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,496,082\n",
      "Trainable params: 109,496,082\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17666/25000 [25:22<10:31, 11.62it/s]"
     ]
    }
   ],
   "source": [
    "#### NER Tagging ###\n",
    "data_csv = r'../data/ner_dataset.csv'\n",
    "tokenizer = Tokenizer(size='base', cased=False)\n",
    "data = Data(data_path=data_csv, \n",
    "            tokenizer=tokenizer,\n",
    "            max_len=125)\n",
    "\n",
    "model = BertModel(saved_model='20230808_bert_model_large.hdf5', data=data)\n",
    "model.model.summary()\n",
    "\n",
    "results = model.results_dataframe(texts=review_df.text.values, include_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
